{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Sarsa 알고리즘 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 구현에 사용할 패키지 임포트하기\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 초기 상태의 미로 모습\n",
    "\n",
    "# 전체 그림의 크기 및 그림을 나타내는 변수 선언\n",
    "fig = plt.figure(figsize=(5, 5))\n",
    "ax = plt.gca()\n",
    "\n",
    "# 붉은 벽 그리기\n",
    "plt.plot([1, 1], [0, 1], color='red', linewidth=2)\n",
    "plt.plot([1, 2], [2, 2], color='red', linewidth=2)\n",
    "plt.plot([2, 2], [2, 1], color='red', linewidth=2)\n",
    "plt.plot([2, 3], [1, 1], color='red', linewidth=2)\n",
    "\n",
    "# 상태를 의미하는 문자열(S0~S8) 표시\n",
    "plt.text(0.5, 2.5, 'S0', size=14, ha='center')\n",
    "plt.text(1.5, 2.5, 'S1', size=14, ha='center')\n",
    "plt.text(2.5, 2.5, 'S2', size=14, ha='center')\n",
    "plt.text(0.5, 1.5, 'S3', size=14, ha='center')\n",
    "plt.text(1.5, 1.5, 'S4', size=14, ha='center')\n",
    "plt.text(2.5, 1.5, 'S5', size=14, ha='center')\n",
    "plt.text(0.5, 0.5, 'S6', size=14, ha='center')\n",
    "plt.text(1.5, 0.5, 'S7', size=14, ha='center')\n",
    "plt.text(2.5, 0.5, 'S8', size=14, ha='center')\n",
    "plt.text(0.5, 2.3, 'START', ha='center')\n",
    "plt.text(2.5, 0.3, 'GOAL', ha='center')\n",
    "\n",
    "# 그림을 그릴 범위 및 눈금 제거 설정\n",
    "ax.set_xlim(0, 3)\n",
    "ax.set_ylim(0, 3)\n",
    "plt.tick_params(axis='both', which='both', bottom=False, top=False,\n",
    "                labelbottom=False, right=False, left=False, labelleft=False)\n",
    "\n",
    "# S0에 녹색 원으로 현재 위치를 표시\n",
    "line, = ax.plot([0.5], [2.5], marker=\"o\", color='g', markersize=60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정책을 결정하는 파라미터의 초깃값 theta_0를 설정\n",
    "\n",
    "# 줄은 상태 0~7, 열은 행동방향(상,우,하,좌 순)를 나타낸다\n",
    "theta_0 = np.array([[np.nan, 1, 1, np.nan],  # s0\n",
    "                    [np.nan, 1, np.nan, 1],  # s1\n",
    "                    [np.nan, np.nan, 1, 1],  # s2\n",
    "                    [1, 1, 1, np.nan],  # s3\n",
    "                    [np.nan, np.nan, 1, 1],  # s4\n",
    "                    [1, np.nan, np.nan, np.nan],  # s5\n",
    "                    [1, np.nan, np.nan, np.nan],  # s6\n",
    "                    [1, 1, np.nan, np.nan],  # s7、※s8은 목표지점이므로 정책이 없다\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정책 파라미터 theta_0을 무작위 행동 정책 pi로 변환하는 함수\n",
    "\n",
    "def simple_convert_into_pi_from_theta(theta):\n",
    "    '''단순 비율 계산'''\n",
    "\n",
    "    [m, n] = theta.shape  # theta의 행렬 크기를 구함\n",
    "    pi = np.zeros((m, n))\n",
    "    for i in range(0, m):\n",
    "        pi[i, :] = theta[i, :] / np.nansum(theta[i, :])  # 비율 계산\n",
    "\n",
    "    pi = np.nan_to_num(pi)  # nan을 0으로 변환\n",
    "\n",
    "    return pi\n",
    "\n",
    "# 무작위 행동정책 pi_0을 계산\n",
    "pi_0 = simple_convert_into_pi_from_theta(theta_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 행동가치 함수 Q의 초기 상태\n",
    "\n",
    "[a, b] = theta_0.shape  # 열과 행의 갯수를 변수 a, b에 저장\n",
    "Q = np.random.rand(a, b) * theta_0\n",
    "# * theta0 로 요소 단위 곱셈을 수행, Q에서 벽 방향으로 이동하는 행동에는 nan을 부여\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ε-greedy 알고리즘 구현\n",
    "\n",
    "\n",
    "def get_action(s, Q, epsilon, pi_0):\n",
    "    direction = [\"up\", \"right\", \"down\", \"left\"]\n",
    "\n",
    "    # 행동을 결정\n",
    "    if np.random.rand() < epsilon:\n",
    "        # 확률 ε로 무작위 행동을 선택함\n",
    "        next_direction = np.random.choice(direction, p=pi_0[s, :])\n",
    "    else:\n",
    "        # Q값이 최대가 되는 행동을 선택함\n",
    "        next_direction = direction[np.nanargmax(Q[s, :])]\n",
    "\n",
    "    # 행동을 인덱스로 변환\n",
    "    if next_direction == \"up\":\n",
    "        action = 0\n",
    "    elif next_direction == \"right\":\n",
    "        action = 1\n",
    "    elif next_direction == \"down\":\n",
    "        action = 2\n",
    "    elif next_direction == \"left\":\n",
    "        action = 3\n",
    "\n",
    "    return action\n",
    "\n",
    "\n",
    "def get_s_next(s, a, Q, epsilon, pi_0):\n",
    "    direction = [\"up\", \"right\", \"down\", \"left\"]\n",
    "    next_direction = direction[a]  # 행동 a의 방향\n",
    "\n",
    "    # 행동으로 다음 상태를 결정\n",
    "    if next_direction == \"up\":\n",
    "        s_next = s - 3  # 위로 이동하면 상태값이 3 줄어든다\n",
    "    elif next_direction == \"right\":\n",
    "        s_next = s + 1  # 오른쪽으로 이동하면 상태값이 1 늘어난다\n",
    "    elif next_direction == \"down\":\n",
    "        s_next = s + 3  # 아래로 이동하면 상태값이 3 늘어난다\n",
    "    elif next_direction == \"left\":\n",
    "        s_next = s - 1  # 왼쪽으로 이동하면 상태값이 1 줄어든다\n",
    "\n",
    "    return s_next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sarsa 알고리즘으로 행동가치 함수 Q를 수정\n",
    "\n",
    "def Sarsa(s, a, r, s_next, a_next, Q, eta, gamma):\n",
    "\n",
    "    if s_next == 8:  # 목표 지점에 도달한 경우\n",
    "        Q[s, a] = Q[s, a] + eta * (r - Q[s, a])\n",
    "\n",
    "    else:\n",
    "        Q[s, a] = Q[s, a] + eta * (r + gamma * Q[s_next, a_next] - Q[s, a])\n",
    "\n",
    "    return Q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sarsa 알고리즘으로 미로를 빠져나오는 함수, 상태 및 행동 그리고 Q값의 히스토리를 출력한다\n",
    "\n",
    "def goal_maze_ret_s_a_Q(Q, epsilon, eta, gamma, pi):\n",
    "    s = 0  # 시작 지점\n",
    "    a = a_next = get_action(s, Q, epsilon, pi)  # 첫 번째 행동\n",
    "    s_a_history = [[0, np.nan]]  # 에이전트의 행동 및 상태의 히스토리를 기록하는 리스트\n",
    "\n",
    "    while (1):  # 목표 지점에 이를 때까지 반복\n",
    "        a = a_next  # 행동 결정\n",
    "\n",
    "        s_a_history[-1][1] = a\n",
    "        # 현재 상태(마지막이므로 인덱스가 -1)을 히스토리에 추가\n",
    "\n",
    "        s_next = get_s_next(s, a, Q, epsilon, pi)\n",
    "        # 다음 단계의 상태를 구함\n",
    "\n",
    "        s_a_history.append([s_next, np.nan])\n",
    "        # 다음 상태를 히스토리에 추가, 행동은 아직 알 수 없으므로 nan으로 둔다\n",
    "\n",
    "        # 보상을 부여하고 다음 행동을 계산함\n",
    "        if s_next == 8:\n",
    "            r = 1  # 목표 지점에 도달했다면 보상을 부여\n",
    "            a_next = np.nan\n",
    "        else:\n",
    "            r = 0\n",
    "            a_next = get_action(s_next, Q, epsilon, pi)\n",
    "            # 다음 행동 a_next를 계산\n",
    "\n",
    "        # 가치함수를 수정\n",
    "        Q = Sarsa(s, a, r, s_next, a_next, Q, eta, gamma)\n",
    "\n",
    "        # 종료 여부 판정\n",
    "        if s_next == 8:  # 목표 지점에 도달하면 종료\n",
    "            break\n",
    "        else:\n",
    "            s = s_next\n",
    "\n",
    "    return [s_a_history, Q]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "에피소드: 1\n",
      "2.9123690381123595\n",
      "목표 지점에 이르기까지 걸린 단계 수는 756단계입니다\n",
      "에피소드: 2\n",
      "0.06470294176990493\n",
      "목표 지점에 이르기까지 걸린 단계 수는 6단계입니다\n",
      "에피소드: 3\n",
      "0.08962131184352168\n",
      "목표 지점에 이르기까지 걸린 단계 수는 16단계입니다\n",
      "에피소드: 4\n",
      "0.07088647193553937\n",
      "목표 지점에 이르기까지 걸린 단계 수는 10단계입니다\n",
      "에피소드: 5\n",
      "0.057825165390497923\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 6\n",
      "0.069115365071926\n",
      "목표 지점에 이르기까지 걸린 단계 수는 10단계입니다\n",
      "에피소드: 7\n",
      "0.055847280693343826\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 8\n",
      "0.0646771466375029\n",
      "목표 지점에 이르기까지 걸린 단계 수는 10단계입니다\n",
      "에피소드: 9\n",
      "0.054024188311407206\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 10\n",
      "0.05343429531742172\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 11\n",
      "0.05278635429752665\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 12\n",
      "0.05207874386146988\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 13\n",
      "0.05131093120979935\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 14\n",
      "0.05048342516236182\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 15\n",
      "0.04959769495031635\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 16\n",
      "0.04865606709232484\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 17\n",
      "0.04766160988053009\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 18\n",
      "0.046618012727305924\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 19\n",
      "0.045529465783242185\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 20\n",
      "0.04440054375731639\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 21\n",
      "0.04323609668999023\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 22\n",
      "0.04204114949695603\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 23\n",
      "0.0408208113716384\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 24\n",
      "0.03958019557152842\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 25\n",
      "0.03832434968616055\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 26\n",
      "0.03705819616729522\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 27\n",
      "0.035786482673166475\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 28\n",
      "0.03451374162070997\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 29\n",
      "0.03324425823770877\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 30\n",
      "0.03198204634869278\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 31\n",
      "0.030730831104155143\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 32\n",
      "0.029494037864122025\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 33\n",
      "0.028274786467673507\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 34\n",
      "0.027075890154329874\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 35\n",
      "0.02589985844703846\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 36\n",
      "0.02474890335638047\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 37\n",
      "0.023624948318948458\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 38\n",
      "0.022529639337513174\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 39\n",
      "0.021464357845061732\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 40\n",
      "0.02043023486784079\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 41\n",
      "0.019428166113352963\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 42\n",
      "0.018458827657222066\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 43\n",
      "0.017522691947583047\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 44\n",
      "0.016620043886945823\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 45\n",
      "0.01575099678924119\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 46\n",
      "0.01491550804395958\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 47\n",
      "0.014113394350067199\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 48\n",
      "0.013344346409800645\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 49\n",
      "0.012607942996720523\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 50\n",
      "0.011903664333717257\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 51\n",
      "0.011230904735219371\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 52\n",
      "0.010588984483891117\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 53\n",
      "0.009977160925812911\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 54\n",
      "0.009394638779763542\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 55\n",
      "0.00884057966594709\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 56\n",
      "0.008314110867547964\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 57\n",
      "0.007814333345034785\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 58\n",
      "0.0073403290283408085\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 59\n",
      "0.006891167416099742\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 60\n",
      "0.006465911514145994\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 61\n",
      "0.006063623147645414\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 62\n",
      "0.00568336768262645\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 63\n",
      "0.005324218193444752\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 64\n",
      "0.004985259112940121\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 65\n",
      "0.004665589401810943\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 66\n",
      "0.004364325273144343\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 67\n",
      "0.004080602507132602\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 68\n",
      "0.003813578389876615\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 69\n",
      "0.0035624333088519755\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 70\n",
      "0.0033263720361560445\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 71\n",
      "0.003104624729090788\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 72\n",
      "0.0028964476760231506\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 73\n",
      "0.002701123813795725\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 74\n",
      "0.0025179630412982545\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 75\n",
      "0.0023463023521538284\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 76\n",
      "0.002185505807833943\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 77\n",
      "0.002034964370928427\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 78\n",
      "0.0018940956167549095\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 79\n",
      "0.0017623433400003607\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 80\n",
      "0.0016391770716805976\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 81\n",
      "0.0015240915203390548\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 82\n",
      "0.0014166059501411477\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 83\n",
      "0.0013162635073069584\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 84\n",
      "0.001222630505198108\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 85\n",
      "0.0011352956773180711\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 86\n",
      "0.0010538694065022058\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 87\n",
      "0.0009779829376552751\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 88\n",
      "0.0009072875805578029\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 89\n",
      "0.0008414539084752315\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 90\n",
      "0.0007801709575961935\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 91\n",
      "0.0007231454316684038\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 92\n",
      "0.0006701009155980486\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 93\n",
      "0.0006207771012446406\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 94\n",
      "0.0005749290281399366\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 95\n",
      "0.0005323263414217516\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 96\n",
      "0.000492752568863164\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 97\n",
      "0.0004560044185274448\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 98\n",
      "0.0004218910982470847\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 99\n",
      "0.00039023365784385255\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 100\n",
      "0.0003608643547524659\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n"
     ]
    }
   ],
   "source": [
    "# Sarsa 알고리즘으로 미로 빠져나오기\n",
    "\n",
    "eta = 0.1  # 학습률\n",
    "gamma = 0.9  # 시간할인율\n",
    "epsilon = 0.5  # ε-greedy 알고리즘 epsilon 초깃값\n",
    "v = np.nanmax(Q, axis=1)  # 각 상태마다 가치의 최댓값을 계산\n",
    "is_continue = True\n",
    "episode = 1\n",
    "\n",
    "while is_continue:  # is_continue의 값이 False가 될 때까지 반복\n",
    "    print(\"에피소드: \" + str(episode))\n",
    "\n",
    "    # ε 값을 조금씩 감소시킴\n",
    "    epsilon = epsilon / 2\n",
    "\n",
    "    # Sarsa 알고리즘으로 미로를 빠져나온 후, 결과로 나온 행동 히스토리와 Q값을 변수에 저장\n",
    "    [s_a_history, Q] = goal_maze_ret_s_a_Q(Q, epsilon, eta, gamma, pi_0)\n",
    "\n",
    "    # 상태가치의 변화\n",
    "    new_v = np.nanmax(Q, axis=1)  # 각 상태마다 행동가치의 최댓값을 계산\n",
    "    print(np.sum(np.abs(new_v - v)))  # 상태가치 함수의 변화를 출력\n",
    "    v = new_v\n",
    "\n",
    "    print(\"목표 지점에 이르기까지 걸린 단계 수는 \" + str(len(s_a_history) - 1) + \"단계입니다\")\n",
    "\n",
    "    # 100 에피소드 반복\n",
    "    episode = episode + 1\n",
    "    if episode > 100:\n",
    "        break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
